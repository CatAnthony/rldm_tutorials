{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pymdptoolbox tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to take a MDP graph and represent it usign pymdptoolbox in python.  Then we will use Value Iteration to find the optimal policy and expected value of the given mdp\n",
    "\n",
    "##The problem\n",
    "A forest is managed by two actions: ‘Wait’ and ‘Cut’. An action is decided each year with first the objective to maintain an old forest for wildlife and second to make money selling cut wood Each year there is a probability p that a fire burns the forest.\n",
    "\n",
    "###Visual Representation \n",
    "![alt text](./mdp.jpeg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "The first thing we need to do is setup matricies for the transition probablities and the rewarewards.  \n",
    "\n",
    "The transition probablities will be represented in a num actions x num states x num states matrix\n",
    "\n",
    "The rewards will be represented in a num states x num actions array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.zeros((2, 5, 5))\n",
    "\n",
    "prob[0] = [[0.3, 0.7, 0., 0., 0.],\n",
    "           [0.3, 0.0, 0.7, 0., 0.],\n",
    "           [0.3, 0.0, 0., 0.7, 0.],\n",
    "           [0.3, 0.0, 0., 0., 0.7],\n",
    "           [0.3, 0.0, 0., 0., 0.7]]\n",
    "\n",
    "prob[1] = [[1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.]]\n",
    "\n",
    "rewards = np.zeros((5, 2))\n",
    "rewards[0] = [0., 0.]\n",
    "rewards[1] = [0., 1.]\n",
    "rewards[2] = [0., 1.]\n",
    "rewards[3] = [0., 1.]\n",
    "rewards[4] = [0.3, 2.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Now we need to setup the MDP in pymdptoolbox and run Value Iteration to get the expected value and optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = mdptoolbox.mdp.ValueIteration(prob, rewards, 0.9)\n",
    "vi.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can extract the optimal policy and expected value of each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy = vi.policy\n",
    "expected_values = vi.V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Putting it all together\n",
    "\n",
    "Here is the final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "import numpy as np\n",
    "\n",
    "prob = np.zeros((2, 5, 5))\n",
    "\n",
    "prob[0] = [[0.3, 0.7, 0., 0., 0.],\n",
    "           [0.3, 0.0, 0.7, 0., 0.],\n",
    "           [0.3, 0.0, 0., 0.7, 0.],\n",
    "           [0.3, 0.0, 0., 0., 0.7],\n",
    "           [0.3, 0.0, 0., 0., 0.7]]\n",
    "\n",
    "prob[1] = [[1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.],\n",
    "           [1., 0., 0., 0., 0.]]\n",
    "\n",
    "rewards = np.zeros((5, 2))\n",
    "rewards[0] = [0., 0.]\n",
    "rewards[1] = [0., 1.]\n",
    "rewards[2] = [0., 1.]\n",
    "rewards[3] = [0., 1.]\n",
    "rewards[4] = [0.3, 2.]\n",
    "\n",
    "vi = mdptoolbox.mdp.ValueIteration(prob, rewards, 0.9)\n",
    "vi.run()\n",
    "\n",
    "optimal_policy = vi.policy\n",
    "expected_values = vi.V\n",
    "\n",
    "print(optimal_policy)\n",
    "print(expected_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
